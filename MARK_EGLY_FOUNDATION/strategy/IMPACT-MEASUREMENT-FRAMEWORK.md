# Mark Egly Foundation - Impact Measurement Framework

**Document Version**: 1.0
**Last Updated**: November 7, 2025
**Owner**: Strategy & Evaluation Team
**Purpose**: Define how we measure, track, and report on our impact in eliminating AATD diagnostic delays

---

## ğŸ“‹ Table of Contents

1. [Framework Overview](#framework-overview)
2. [Impact Measurement Philosophy](#impact-measurement-philosophy)
3. [Primary Impact Metric](#primary-impact-metric)
4. [Program-Level Metrics](#program-level-metrics)
5. [Data Collection Methods](#data-collection-methods)
6. [Reporting & Dashboards](#reporting--dashboards)
7. [Evaluation Schedule](#evaluation-schedule)

---

## Framework Overview

### What Is Impact Measurement?

Impact measurement is how we answer the question: **"Are we achieving our mission?"**

For the Mark Egly Foundation, this means:

- âœ… Are diagnostic delays decreasing?
- âœ… Are more patients being diagnosed earlier?
- âœ… Are health outcomes improving?
- âœ… Are systems changing (policy, medical practice)?

### Our Measurement Approach

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INPUTS â†’ ACTIVITIES â†’ OUTPUTS â†’ OUTCOMES â†’ IMPACT     â”‚
â”‚                                                         â”‚
â”‚  What we     What we      What we      What           Ultimate  â”‚
â”‚  invest      do           produce      changes         goal      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

We measure at **all five levels**:

1. **Inputs**: Resources invested (money, time, partnerships)
2. **Activities**: Programs executed (CME courses, grants, advocacy)
3. **Outputs**: Direct results (physicians trained, patients served)
4. **Outcomes**: Changes in behavior/systems (earlier testing, policy wins)
5. **Impact**: Ultimate goal achieved (diagnostic delays eliminated)

---

## Impact Measurement Philosophy

### Guiding Principles

**1. Mission-Driven Metrics**

- Every metric ties back to our mission: eliminate diagnostic delays
- If a metric doesn't inform our strategy, we don't track it
- Quality over quantity (meaningful impact > vanity metrics)

**2. Patient-Centered**

- Patient outcomes are the ultimate measure of success
- Patient voices included in evaluation
- We measure what matters to patients, not just what's easy to count

**3. Evidence-Based**

- Data-driven decision making
- Rigorous evaluation methods
- Honest assessment (celebrate wins, learn from failures)

**4. Transparent Reporting**

- Publish impact data annually
- Share successes AND challenges
- Invite external evaluation

**5. Continuous Improvement**

- Metrics inform strategy adjustments
- Quarterly reviews for course correction
- Willingness to pivot if something isn't working

### What Success Looks Like

**Short-Term Success** (1-2 years):

- Programs launched and scaling
- Early adoption by physicians
- Patient community growing
- Awareness increasing

**Medium-Term Success** (3-5 years):

- Measurable decrease in diagnostic delay
- Policy wins in multiple states
- Research innovations advancing
- National recognition as AATD leader

**Long-Term Success** (5-10 years):

- Diagnostic delay cut in half
- Systemic change achieved
- Universal newborn screening
- Model replicated for other rare diseases

---

## Primary Impact Metric

### Diagnostic Delay Time (DDT)

**Definition**: Average time from first symptom presentation to confirmed AATD diagnosis

**Why This Metric?**

- âœ… Directly measures our mission
- âœ… Captures cumulative impact of all programs
- âœ… Meaningful to patients (lived experience)
- âœ… Comparable over time (trend analysis)

**Measurement Method**:

```
For each newly diagnosed patient, calculate:

DDT = Date of Diagnosis - Date of First AATD-Related Symptom

Example:
- First symptom (shortness of breath): January 2018
- Diagnosis: March 2025
- DDT = 7 years, 2 months
```

**Data Collection**:

- Annual survey of newly diagnosed patients (sample size: 500+)
- Questions:
  - When did you first experience symptoms?
  - When were you diagnosed?
  - How many physicians did you see?
  - What were you initially diagnosed with?
  - How did you finally get diagnosed?

**Baseline & Targets**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DIAGNOSTIC DELAY TIME (Years)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Baseline (2025):     7-8 years                         â”‚
â”‚  Target Year 1 (2026): 7-8 years (building phase)       â”‚
â”‚  Target Year 2 (2027): 6-7 years (early impact)         â”‚
â”‚  Target Year 3 (2028): 5-6 years (measurable change)    â”‚
â”‚  Target Year 4 (2029): 4-5 years (acceleration)         â”‚
â”‚  Target Year 5 (2030): 3-4 years âœ… (GOAL)              â”‚
â”‚                                                         â”‚
â”‚  Long-Term (2035):    <1 year (ultimate vision)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Statistical Analysis**:

- Mean and median DDT
- Distribution (25th, 50th, 75th percentile)
- Year-over-year change
- Statistical significance testing
- Subgroup analysis (age, geography, genotype)

**Reporting**:

- Published annually in impact report
- Trend line visualization
- Confidence intervals included
- Methodology transparent

---

## Program-Level Metrics

### Education Programs

#### Metric 1: Physicians Trained

**Definition**: Number of physicians who complete CME course "Recognizing AATD in Primary Care"

**Targets**:

- Year 1: 1,000 physicians
- Year 2: 6,000 (cumulative: 6,000)
- Year 3: 25,000 (cumulative: 25,000)
- Year 4: 40,000 (cumulative: 40,000)
- Year 5: 60,000 (cumulative: 60,000)

**Data Source**: CME platform enrollment/completion data

**Reporting**: Quarterly

---

#### Metric 2: Behavior Change (Testing Frequency)

**Definition**: % of trained physicians who report testing for AATD more frequently

**Measurement**:

- Baseline survey: "How often do you test for AATD?"
- Follow-up survey (6 months post-training): Same question
- Calculate % who increased testing frequency

**Target**: 60%+ of trained physicians test more frequently

**Data Source**: Pre/post surveys embedded in CME course

**Reporting**: Semi-annually

---

#### Metric 3: AATD Aware Institutions

**Definition**: Number of medical institutions certified as "AATD Aware"

**Certification Criteria**:

- âœ… 80%+ physicians trained
- âœ… AATD testing protocol in place
- âœ… Patient education materials available
- âœ… Cascade testing policy
- âœ… Annual screening data reported

**Targets**:

- Year 1: 10 institutions
- Year 2: 50 institutions (cumulative)
- Year 3: 250 institutions (cumulative)
- Year 4: 600 institutions (cumulative)
- Year 5: 1,000 institutions (cumulative)

**Data Source**: Certification applications and audits

**Reporting**: Quarterly

---

#### Metric 4: Public Awareness

**Definition**: % of US adults who have heard of AATD

**Measurement**: National survey (representative sample)

**Questions**:

- "Have you heard of Alpha-1 Antitrypsin Deficiency (AATD)?"
- "Do you know what AATD is?" (awareness vs. understanding)
- "Would you know how to get tested if concerned?"

**Baseline** (2025): ~5% awareness (estimated)

**Targets**:

- Year 1: 8% awareness
- Year 2: 12% awareness
- Year 3: 20% awareness
- Year 4: 30% awareness
- Year 5: 40% awareness

**Data Source**: Annual national survey (commissioned)

**Reporting**: Annually

---

### Support Programs

#### Metric 5: Patients Financially Assisted

**Definition**: Number of patients who receive foundation financial assistance for testing or treatment

**Categories**:

- Testing assistance (genetic testing)
- Treatment assistance (AAT augmentation therapy)
- Cascade testing (family members)

**Targets**:

- Year 1: 500 patients
- Year 2: 2,500 patients (cumulative)
- Year 3: 10,000 patients (cumulative)
- Year 4: 25,000 patients (cumulative)
- Year 5: 50,000 patients (cumulative)

**Outcome Tracking**:

- % who receive testing assistance â†’ get diagnosed
- % who receive treatment assistance â†’ start therapy
- Time from assistance to diagnosis/treatment

**Data Source**: Patient assistance database (CRM)

**Reporting**: Monthly (internal), Quarterly (external)

---

#### Metric 6: Patient Navigation Impact

**Definition**: Outcomes for patients who receive navigation services

**Metrics**:

- **Time to first treatment**: Days from diagnosis to treatment start
  - Target: <90 days (vs. 180+ days baseline)
- **Patient satisfaction (NPS)**: Net Promoter Score
  - Target: 80+ NPS
- **Treatment adherence**: % still on treatment at 12 months
  - Target: 90%+ adherence

**Data Collection**:

- Navigator case notes (CRM)
- Patient surveys (intake, 3 months, 6 months, 12 months)
- Treatment adherence tracking

**Data Source**: Patient navigation database

**Reporting**: Quarterly

---

#### Metric 7: Community Engagement (Alpha1Life.com)

**Definition**: Engagement metrics for patient community platform

**Metrics**:

- **Total Members**: Registered users
  - Year 5 Target: 25,000 members
- **Monthly Active Users (MAU)**: Users who log in monthly
  - Target: 40% of total members
- **Engagement Rate**: Posts, comments, interactions
  - Target: 15% of MAU engage weekly
- **Satisfaction**: Community satisfaction survey
  - Target: 4.5/5 stars

**Data Source**: Platform analytics (Google Analytics, custom dashboards)

**Reporting**: Monthly (internal), Quarterly (board)

---

### Research Programs

#### Metric 8: Research Funding Facilitated

**Definition**: Total $ in research grants awarded or partnerships facilitated

**Categories**:

- Direct grants from foundation
- Leveraged funding (foundation grant enables larger funding)
- Partnership-facilitated funding

**Targets**:

- Year 1: $250K
- Year 2: $1.25M (cumulative)
- Year 3: $4.25M (cumulative)
- Year 4: $10M+ (cumulative) âœ… GOAL
- Year 5: $15M+ (cumulative)

**Outcome Tracking**:

- Publications resulting from grants
- Innovations developed
- Clinical trials initiated
- Patient lives impacted

**Data Source**: Grant management system

**Reporting**: Quarterly

---

#### Metric 9: AAT Glucometer Development

**Definition**: Progress milestones for AAT monitoring device

**Milestones** (Year 1-5):

- âœ… Year 1: Feasibility study complete
- âœ… Year 1: Prototype developed
- âœ… Year 2: Beta testing (50 patients)
- âœ… Year 3: FDA approval submitted
- âœ… Year 3: FDA approval received
- âœ… Year 4: Commercial launch
- âœ… Year 5: 10,000+ users

**Post-Launch Metrics**:

- Number of devices sold/distributed
- User satisfaction
- Clinical outcomes (exacerbations prevented)
- Cost per patient

**Data Source**: Development partner reports, sales data, user surveys

**Reporting**: Quarterly (milestones), Monthly post-launch (sales)

---

#### Metric 10: Data Donation Program

**Definition**: Number of patients enrolled in anonymous data donation program

**Targets**:

- Year 1: 1,000 patients
- Year 2: 4,000 patients (cumulative)
- Year 3: 10,000 patients (cumulative)
- Year 4: 20,000 patients (cumulative)
- Year 5: 30,000 patients (cumulative)

**Data Utility Metrics**:

- Number of researchers accessing database
- Publications using foundation data
- Discoveries/insights enabled

**Data Source**: Data donation platform

**Reporting**: Semi-annually

---

### Advocacy Programs

#### Metric 11: Newborn Screening Legislation

**Definition**: Number of states that pass legislation adding AATD to newborn screening panel

**Targets**:

- Year 1: 0 states (bills introduced in 3 states)
- Year 2: 2 states âœ… (bills passed)
- Year 3: 5 states âœ… (bills passed, cumulative)
- Year 4: 8 states (cumulative)
- Year 5: 10+ states âœ… GOAL (cumulative)

**Pipeline Tracking**:

- States with champions identified
- Bills drafted
- Bills introduced
- Bills in committee
- Bills passed one chamber
- Bills signed into law
- Implementation started

**Data Source**: Legislative tracking database

**Reporting**: Monthly (internal), Quarterly (external)

---

#### Metric 12: Insurance Coverage

**Definition**: Number of major insurance companies with mandated AATD coverage

**Coverage Components**:

- âœ… Genetic testing (no prior auth)
- âœ… AAT augmentation therapy
- âœ… Monitoring (including glucometer)
- âœ… Pulmonary rehabilitation

**Targets**:

- Year 1: 0 (negotiations initiated with 5 insurers)
- Year 2: 1 major insurer
- Year 3: 3 major insurers âœ…
- Year 4: 5+ major insurers (all major carriers)
- Year 5: Medicare/Medicaid mandates

**Impact Measurement**:

- Number of covered lives
- % of AATD patients with coverage
- Reduction in out-of-pocket costs

**Data Source**: Insurance partnership agreements

**Reporting**: Quarterly

---

#### Metric 13: Media & Public Reach

**Definition**: Total media impressions generated through advocacy efforts

**Channels**:

- Earned media (press coverage)
- Social media reach
- Paid advertising impressions
- Event attendance

**Targets**:

- Year 1: 10M impressions
- Year 2: 50M impressions
- Year 3: 100M impressions
- Year 4: 250M impressions
- Year 5: 500M impressions

**Quality Metrics**:

- Message consistency (% mentioning diagnostic delay)
- Sentiment analysis (positive/neutral/negative)
- Call-to-action results (website traffic, donations)

**Data Source**: Media monitoring service, analytics platforms

**Reporting**: Monthly

---

### Organizational Metrics

#### Metric 14: Financial Health

**Metrics**:

- **Revenue vs. Goal**: % of annual fundraising goal achieved
  - Target: 100%+ annually
- **Expense Ratio**: Program expenses / Total expenses
  - Target: 80%+ to programs (20% or less to overhead)
- **Operating Reserve**: Months of expenses in reserve
  - Target: 6 months by Year 3
- **Donor Retention**: % of donors who give again next year
  - Target: 60%+ retention

**Data Source**: Financial management system (QuickBooks, Salesforce)

**Reporting**: Monthly (internal), Quarterly (board), Annually (public)

---

#### Metric 15: Organizational Capacity

**Metrics**:

- **Staff Count**: Number of full-time equivalent employees
  - Year 5 Target: 40 staff
- **Board Engagement**: Board meeting attendance, giving participation
  - Target: 90%+ attendance, 100% board giving
- **Volunteer Hours**: Total volunteer hours contributed
  - Year 5 Target: 10,000+ hours/year
- **Partnership Count**: Active strategic partnerships
  - Year 5 Target: 50+ partners

**Data Source**: HR systems, volunteer management database

**Reporting**: Quarterly

---

## Data Collection Methods

### Quantitative Data

**1. Database Systems**

- **CRM (Salesforce)**: Patient assistance, navigation, donor management
- **CME Platform**: Course enrollment, completion, pre/post surveys
- **Website Analytics**: Google Analytics for website and Alpha1Life.com
- **Financial System**: QuickBooks for all financial data
- **Grant Management**: Custom database for research grants

**2. Surveys**

**Patient Surveys**:

- Diagnostic Journey Survey (annual, n=500+)
- Patient Satisfaction (NPS) Survey (quarterly, all navigation patients)
- Community Engagement Survey (annual, Alpha1Life.com members)

**Physician Surveys**:

- Baseline AATD Awareness Survey (pre-CME)
- Follow-up Testing Behavior Survey (6 months post-CME)
- Annual National Physician Survey (n=1,000, representative sample)

**General Public Surveys**:

- Annual National Awareness Survey (n=2,000, representative sample)

**3. Administrative Data**

- Legislative tracking database
- Media monitoring service
- Insurance company partnership agreements
- Research publication tracking (PubMed, Google Scholar)

---

### Qualitative Data

**1. Patient Stories**

- In-depth interviews with patients (10-20 annually)
- Focus groups with patient community (quarterly)
- Testimonials and case studies
- Open-ended survey questions

**2. Stakeholder Interviews**

- Physician interviews (understanding barriers/facilitators)
- Legislator/policymaker interviews (policy impact)
- Partner organization interviews (collaboration effectiveness)

**3. Observational Data**

- Site visits to certified institutions
- Support group observations
- Conference/event participation

**4. Document Review**

- Media coverage analysis (content and tone)
- Legislative testimony and public comments
- Social media content analysis

---

### Data Quality & Ethics

**Data Quality Standards**:

- âœ… Accurate: Regular data audits and validation
- âœ… Complete: Minimize missing data
- âœ… Consistent: Standardized definitions and collection methods
- âœ… Timely: Real-time or near-real-time data entry

**Ethical Considerations**:

- âœ… **Privacy**: HIPAA compliance for all patient data
- âœ… **Consent**: Informed consent for surveys and data donation
- âœ… **Security**: Encrypted data storage and transmission
- âœ… **De-identification**: Remove PII from research data
- âœ… **IRB Approval**: For research studies involving human subjects

**Data Governance**:

- Data Management Policy (who can access what)
- Data Retention Policy (how long to keep data)
- Data Sharing Policy (when/how to share with researchers)
- Annual security audit

---

## Reporting & Dashboards

### Internal Dashboards (Real-Time)

**Executive Dashboard** (viewed by leadership weekly):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MARK EGLY FOUNDATION - EXECUTIVE DASHBOARD             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PRIMARY IMPACT METRIC                                  â”‚
â”‚  Diagnostic Delay Time: 7.2 years (â†“ 0.3 vs. baseline) â”‚
â”‚                                                         â”‚
â”‚  EDUCATION                                              â”‚
â”‚  Physicians Trained: 8,234 (Goal: 6,000) âœ…            â”‚
â”‚  AATD Aware Institutions: 45 (Goal: 50) ğŸŸ¡             â”‚
â”‚                                                         â”‚
â”‚  SUPPORT                                                â”‚
â”‚  Patients Assisted: 1,823 (Goal: 2,500) ğŸŸ¡             â”‚
â”‚  Patient NPS: 87 (Goal: 80+) âœ…                         â”‚
â”‚                                                         â”‚
â”‚  RESEARCH                                               â”‚
â”‚  Research Funding: $1.1M (Goal: $1.25M) ğŸŸ¡             â”‚
â”‚  Glucometer Milestone: Beta Testing âœ…                  â”‚
â”‚                                                         â”‚
â”‚  ADVOCACY                                               â”‚
â”‚  States with Legislation: 2 passed, 5 introduced âœ…     â”‚
â”‚  Media Impressions: 48M (Goal: 50M) ğŸŸ¡                 â”‚
â”‚                                                         â”‚
â”‚  FINANCIAL                                              â”‚
â”‚  Revenue vs. Goal: $1.4M / $1.5M (93%) ğŸŸ¡              â”‚
â”‚  Expense Ratio: 82% to programs âœ…                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… On Track    ğŸŸ¡ Attention Needed    ğŸ”´ Off Track
```

**Program Dashboards** (viewed by program directors weekly):

- Education Dashboard (CME enrollments, completion rates, certifications)
- Support Dashboard (patients served, NPS, navigation outcomes)
- Research Dashboard (grant pipeline, publications, AAT glucometer progress)
- Advocacy Dashboard (legislative tracking, coalition partners, media)

---

### External Reporting

#### Quarterly Impact Report (for donors, board, partners)

**Structure**:

1. **Executive Summary**: Highlights and key wins
2. **Progress vs. Goals**: All metrics vs. targets
3. **Program Spotlight**: Deep dive on one program
4. **Patient Story**: Humanize the data
5. **Challenges & Learnings**: Honest assessment
6. **Next Quarter Priorities**: What's ahead

**Distribution**:

- Email to all donors and partners
- Posted on website (public transparency)
- Presented at quarterly board meeting

---

#### Annual Impact Report (comprehensive public report)

**Structure**:

1. **Letter from Founder**: Mark's message
2. **Year in Review**: Major accomplishments
3. **Primary Impact Metric**: Diagnostic delay trend analysis
4. **Program Reports**: All four pillars (Education, Support, Research, Advocacy)
5. **Patient Stories**: 5-10 in-depth stories
6. **Financial Report**: Revenue, expenses, Form 990 summary
7. **Looking Ahead**: Next year's goals
8. **Acknowledgments**: Donors, volunteers, partners

**Format**:

- PDF report (40-50 pages)
- Interactive web version
- Executive summary one-pager
- Social media highlights

**Distribution**:

- Mailed to major donors
- Posted on website
- Promoted via social media
- Submitted to GuideStar, Charity Navigator

---

#### Specialized Reports

**1. Research Impact Report** (annually)

- All research grants awarded
- Publications and discoveries
- AAT glucometer development update
- Data donation program summary

**2. Advocacy Impact Report** (annually)

- Legislative wins and setbacks
- State-by-state progress map
- Policy analysis
- Next year's advocacy agenda

**3. Financial Transparency Report** (annually)

- Detailed financial statements
- Donor acknowledgments (with permission)
- Investment policy and performance
- Executive compensation

---

### Public Data Visualization

**Website Impact Dashboard** (public-facing):

- Real-time metrics (updated monthly)
- Interactive visualizations
- Geographic maps (where we work)
- Patient testimonial videos
- "Download the data" option (open data)

**Example Visualizations**:

- Line chart: Diagnostic delay trend over time
- Map: States with newborn screening legislation
- Bar chart: Physicians trained by year
- Infographic: Patient journey timeline

---

## Evaluation Schedule

### Continuous Monitoring

**Weekly**:

- Leadership team reviews executive dashboard
- Flag any red/yellow indicators for attention

**Monthly**:

- Program directors submit progress reports
- Finance team reviews budget vs. actuals
- Fundraising team reviews donor pipeline

**Quarterly**:

- Quarterly Impact Report published
- Board meeting with dashboard review
- Program deep-dives (rotate focus)
- Strategic adjustments if needed

---

### Annual Evaluation

**Process**:

**Q1 (Nov-Jan)**:

1. Collect all annual data
2. Conduct patient diagnostic journey survey
3. Commission national awareness survey
4. Analyze year-over-year trends

**Q2 (Feb-Apr)**: 5. Stakeholder interviews (patients, physicians, partners) 6. Program effectiveness analysis 7. Draft Annual Impact Report 8. Board strategic review session

**Q3 (May-Jul)**: 9. Publish Annual Impact Report 10. Host public webinar on findings 11. Submit reports to rating agencies 12. Media outreach on impact

**Q4 (Aug-Oct)**: 13. Incorporate learnings into next year's plan 14. Adjust metrics if needed 15. Set next year's targets 16. Update Theory of Change if needed

---

### Mid-Point Evaluation (Year 3)

**Purpose**: Comprehensive external evaluation to assess:

- Are we on track to achieve our 5-year goal?
- Is our theory of change valid (do our programs lead to impact)?
- What adjustments should we make for years 4-5?

**Process**:

1. **Hire External Evaluator**: Independent evaluation firm
2. **Comprehensive Data Collection**:
   - Review all quantitative data (3 years)
   - Conduct 50+ stakeholder interviews
   - Survey patients, physicians, partners
   - Site visits to certified institutions
3. **Analysis**:
   - Outcomes vs. baseline
   - Program effectiveness
   - Cost per outcome
   - Theory of change validation
4. **Report**:
   - External evaluation report (50+ pages)
   - Recommendations for improvement
   - Public summary published
5. **Strategic Adjustment**:
   - Board retreat to review findings
   - Revise strategic plan if needed
   - Update metrics framework
   - Communicate changes to stakeholders

---

### Long-Term Impact Study (Year 10)

**Purpose**: Measure ultimate impact 10 years after launch

**Research Questions**:

- Has diagnostic delay decreased as predicted?
- What is the health impact on patients diagnosed earlier?
- What systemic changes have occurred (policy, medical practice)?
- What is the return on investment (lives saved, costs avoided)?
- Can our model be replicated for other rare diseases?

**Methods**:

- Retrospective cohort study (patients diagnosed 2025 vs. 2035)
- Health outcomes comparison (lung function, quality of life, mortality)
- Economic analysis (healthcare costs saved)
- Policy analysis (legislation passed, implementation effectiveness)
- Case study of foundation's role in change

---

## Success Celebration & Learning

### When We Hit Milestones

**Celebrate**:

- ğŸ‰ Public announcement (press release)
- ğŸ‰ Internal celebration (staff/volunteer recognition)
- ğŸ‰ Share patient stories
- ğŸ‰ Thank donors and partners

**Learn**:

- What worked? (document best practices)
- Can we replicate this success elsewhere?
- What surprised us?

---

### When We Miss Targets

**Honest Assessment**:

- Why did we miss the target? (root cause analysis)
- Was the target unrealistic?
- Did we execute poorly?
- Were there external factors?

**Learn & Adapt**:

- Adjust strategy if needed
- Revise targets if appropriate
- Communicate transparently (don't hide failures)
- Recommit to mission

**Example Response**:

> "We set a goal to train 5,000 physicians this year but only reached 3,200. After analysis, we discovered that our free CME approach led to low completion rates (40%). In response, we're adding incentives (malpractice insurance discounts) and shortening the course. We're confident these changes will help us exceed next year's goal."

---

## Summary: Measuring What Matters

The Mark Egly Foundation measures impact at multiple levels:

**âœ… Primary Impact**: Diagnostic delay reduction (ultimate goal)
**âœ… Program Outcomes**: Education, Support, Research, Advocacy metrics
**âœ… Organizational Health**: Financial, capacity, partnership strength

**Our commitment**:

- ğŸ“Š **Data-driven** decision making
- ğŸ” **Transparent** reporting (share everything publicly)
- ğŸ“ˆ **Continuous improvement** (learn and adapt)
- ğŸ’™ **Patient-centered** (measure what matters to patients)

**By 2030**, we will have rigorous data proving that our multi-pronged approach works. We will share our model openly so other rare disease foundations can replicate our success.

**This is how we ensure Mark's vision becomes reality.**

---

**Approved by**: Mark Egly Foundation Board of Directors
**Effective Date**: November 7, 2025
**Review Date**: Quarterly (metrics), Annually (framework), Year 3 (comprehensive evaluation)
**Version**: 1.0

---

_"In data, we trust. In impact, we measure. In patients, we believe."_

**â€” Mark Egly Foundation Evaluation Team**
