# Medical Content Standards

## Executive Summary

**Medical Content Standards** ensure that all information shared on Uniting Doctors meets rigorous quality, accuracy, and safety requirements. These standards protect healthcare professionals and patients while fostering evidence-based discourse and maintaining the platform's credibility as a trusted medical information source.

---

## Table of Contents

1. [Core Principles](#core-principles)
2. [Content Classification](#content-classification)
3. [Evidence Hierarchy](#evidence-hierarchy)
4. [Citation Requirements](#citation-requirements)
5. [Medical Accuracy Verification](#medical-accuracy-verification)
6. [Content Review Process](#content-review-process)
7. [Disclaimers & Warnings](#disclaimers--warnings)
8. [Quality Metrics](#quality-metrics)

---

## Core Principles

### 1. Evidence-Based Medicine

**Standard**: All clinical recommendations must be supported by peer-reviewed evidence or established clinical guidelines.

**Requirements**:

- Citations to primary sources (peer-reviewed journals, clinical trials)
- Reference to clinical practice guidelines (AHA, ACC, ESC, NICE, etc.)
- Clear distinction between evidence-based practice and expert opinion
- Disclosure of evidence quality (high, moderate, low)

### 2. Patient Safety First

**Standard**: Content must not pose risk to patient safety.

**Prohibited Content**:

- Dangerous medical advice without proper context
- Encouragement to discontinue medications without physician consultation
- Unproven treatments presented as standard care
- Diagnostic advice that could delay proper medical evaluation

### 3. Transparency & Disclosure

**Requirements**:

- Conflicts of interest disclosed (pharmaceutical ties, financial relationships)
- Uncertainty acknowledged when evidence is limited
- Off-label uses clearly labeled
- Limitations of observational data noted

### 4. Professional Standards

**Standard**: Content must align with professional medical ethics and standards of care.

**Guidelines**:

- Respect patient autonomy and informed consent
- Maintain professional tone and terminology
- Avoid sensationalism or fear-mongering
- Respect cultural and ethical diversity in medicine

---

## Content Classification

### Level 1: Peer-Reviewed Research

**Source**: Published in peer-reviewed medical journals

**Quality Indicators**:

- âœ… Peer-reviewed
- âœ… DOI/PMID present
- âœ… Impact factor > 2.0 (preferred)
- âœ… Methodology clearly described

**Display Badge**: ğŸ”¬ **Peer-Reviewed Research**

**Standards**:

- Full citation required
- Abstract must be accessible
- Key findings summarized
- Limitations discussed

### Level 2: Clinical Guidelines

**Source**: Professional medical societies (AHA, ACS, IDSA, etc.)

**Quality Indicators**:

- âœ… Published by recognized medical organization
- âœ… Evidence-graded recommendations (Class I, IIa, IIb, III)
- âœ… Updated within last 5 years
- âœ… Conflict of interest statements included

**Display Badge**: ğŸ“‹ **Clinical Guideline**

**Standards**:

- Guideline name and year cited
- Recommendation class specified
- Evidence level indicated (A, B, C)
- Link to full guideline

### Level 3: Expert Commentary

**Source**: Verified medical professionals sharing clinical experience

**Quality Indicators**:

- âœ… Author credentials verified
- âœ… Specialty relevance
- âœ… Evidence-informed opinion
- âš ï¸ Personal experience, not research

**Display Badge**: ğŸ’­ **Expert Opinion**

**Standards**:

- Clearly labeled as opinion/experience
- Evidence cited when available
- Limitations acknowledged
- Not presented as definitive guidance

### Level 4: Case Reports

**Source**: Individual patient cases shared for educational purposes

**Quality Indicators**:

- âœ… HIPAA-compliant (de-identified)
- âœ… Educational value
- âœ… Outcome reported
- âš ï¸ Anecdotal, not generalizable

**Display Badge**: ğŸ“Š **Case Report**

**Standards**:

- All identifiable information removed
- Relevant clinical details included
- Outcome and lessons learned described
- Warning: "Single case, not generalizable"

### Level 5: Medical News

**Source**: Reputable medical news outlets

**Quality Indicators**:

- âœ… Reputable source (Reuters Health, MedPage Today, STAT)
- âœ… Original study linked
- âœ… Publication date < 30 days
- âš ï¸ Journalistic interpretation, not original research

**Display Badge**: ğŸ“° **Medical News**

**Standards**:

- Original source cited
- Key findings summarized
- Context provided (trial size, duration, limitations)
- Disclaimer: "News summary, refer to original research"

---

## Evidence Hierarchy

**Evidence Quality Ranking** (Oxford Centre for Evidence-Based Medicine):

### Level 1a: Systematic Reviews of RCTs

- **Gold Standard**
- Meta-analyses of multiple randomized controlled trials
- Cochrane reviews preferred
- Display: â­â­â­â­â­ **Highest Quality Evidence**

### Level 1b: Individual RCTs

- **High Quality**
- Well-designed randomized controlled trials
- Adequate sample size and follow-up
- Display: â­â­â­â­ **High Quality Evidence**

### Level 2a: Systematic Reviews of Cohort Studies

- **Moderate Quality**
- Well-conducted observational studies
- Display: â­â­â­ **Moderate Quality Evidence**

### Level 2b: Individual Cohort Studies

- **Moderate Quality**
- Prospective cohort studies
- Display: â­â­â­ **Moderate Quality Evidence**

### Level 3: Case-Control Studies

- **Lower Quality**
- Retrospective designs
- Display: â­â­ **Limited Evidence**

### Level 4: Case Series / Case Reports

- **Lowest Quality**
- Anecdotal evidence
- Display: â­ **Anecdotal Evidence**

### Level 5: Expert Opinion

- **Opinion-Based**
- Clinical experience without systematic evidence
- Display: ğŸ’­ **Expert Opinion** (No star rating)

**Evidence Grading Example**:

```markdown
## Treatment Recommendation: Beta-blockers for Heart Failure

**Evidence Level**: â­â­â­â­â­ Level 1a (Systematic Review of RCTs)

**Source**:

- MERIT-HF, COPERNICUS, CIBIS trials (combined n=10,000+)
- Cochrane Review: Beta-blockers for CHF (2018)

**Recommendation**:
Class I (Benefit >>> Risk)
Evidence Level A (Multiple RCTs)

**Effect Size**:

- 35% reduction in all-cause mortality
- NNT = 25 to prevent 1 death over 2 years
```

---

## Citation Requirements

### Mandatory Citations

**Clinical Recommendations**:

- Must cite at least 1 peer-reviewed source
- Guideline recommendations cite original guideline
- Off-label uses cite supporting evidence

**Statistical Claims**:

- "X% of patients..." requires citation
- Risk ratios, hazard ratios, p-values must be sourced
- Sample sizes reported

**Drug Information**:

- FDA approval status cited
- Dosing recommendations cite prescribing information
- Adverse effects cite pharmacovigilance data

### Citation Format

**Standard Format** (Modified Vancouver Style):

```
Author(s). Title. Journal. Year;Volume(Issue):Pages. DOI/PMID.

Example:
Smith J, Doe A. Beta-blockers in heart failure. N Engl J Med. 2024;390(12):1045-1056.
doi:10.1056/NEJMoa2024001. PMID:38234567.
```

**Simplified In-Text Citations**:

```markdown
Beta-blockers reduce mortality in HFrEF by 35% [1,2].

[1] MERIT-HF Study (Lancet, 1999)
[2] Cochrane Review: Beta-blockers for CHF (2018)
```

### Acceptable Sources

**âœ… Acceptable**:

- Peer-reviewed medical journals
- Clinical practice guidelines from medical societies
- FDA/EMA/regulatory agency publications
- UpToDate, DynaMed (clinical decision support)
- PubMed-indexed literature

**âš ï¸ Use with Caution**:

- Pre-print servers (bioRxiv, medRxiv) - clearly labeled
- Conference abstracts - preliminary data noted
- Institutional protocols - context-specific

**âŒ Not Acceptable**:

- Wikipedia as primary source
- Commercial pharmaceutical websites (non-peer-reviewed)
- Social media posts
- Non-peer-reviewed blogs
- Patient advocacy sites (for clinical claims)

---

## Medical Accuracy Verification

### AI-Powered Fact-Checking

**Automated Verification**:

```python
async def verify_medical_claim(claim_text):
    """
    Use GPT-4 + PubMed to verify medical claims
    """
    # Step 1: Extract medical assertions
    assertions = extract_claims(claim_text)

    verification_results = []
    for assertion in assertions:
        # Step 2: Search PubMed for supporting evidence
        evidence = await search_pubmed(assertion)

        # Step 3: GPT-4 fact-check
        prompt = f"""
        Medical Claim: "{assertion}"

        PubMed Evidence:
        {evidence}

        Assess accuracy:
        1. Accurate (well-supported by evidence)
        2. Partially accurate (evidence mixed)
        3. Inaccurate (contradicted by evidence)
        4. Unverifiable (insufficient evidence)

        Provide assessment and brief explanation.
        """

        result = await gpt4_evaluate(prompt)
        verification_results.append({
            'claim': assertion,
            'assessment': result.accuracy,
            'explanation': result.explanation,
            'supporting_evidence': evidence[:3]  # Top 3 sources
        })

    return verification_results
```

**Verification Results Display**:

```
âœ… Verified: "Beta-blockers reduce mortality in HFrEF"
   Evidence: 12 RCTs, 3 systematic reviews support this claim

âš ï¸ Partially Verified: "Most patients tolerate beta-blockers well"
   Evidence: Mixed data on tolerability (60-80% depending on population)

âŒ Inaccurate: "Beta-blockers cure heart failure"
   Evidence: Beta-blockers improve outcomes but do not cure HF

â“ Unverifiable: "Patients feel better within 24 hours"
   Evidence: Insufficient data on symptom onset timing
```

### Human Expert Review

**Review Process**:

1. **Automated Screening**: AI flags potential issues
2. **Peer Review**: High-reputation users can review flagged content
3. **Expert Panel**: Complex cases reviewed by specialty experts
4. **Editorial Board**: Final review for featured/promoted content

**Reviewer Qualifications**:

- Reputation score > 800
- Specialty expertise relevant to content
- No conflicts of interest
- Track record of quality contributions

**Review Criteria**:

- Medical accuracy
- Evidence quality
- Completeness
- Clarity and readability
- Appropriate disclaimers
- Citation adequacy

---

## Content Review Process

### Submission Review

**New Content Workflow**:

```
User Submits Content
    â†“
Automated Checks (AI)
â”œâ”€â”€ Spam detection
â”œâ”€â”€ Medical term extraction
â”œâ”€â”€ Citation validation
â”œâ”€â”€ Plagiarism check
â””â”€â”€ Initial quality score
    â†“
[Score > 70] â†’ Published immediately with monitoring
[Score 40-70] â†’ Queue for peer review
[Score < 40] â†’ Rejected with feedback
```

### Post-Publication Monitoring

**Continuous Quality Assurance**:

- Community flagging system
- Periodic re-review of high-traffic content
- Updates when new evidence emerges
- Retraction notices for outdated/incorrect information

**Update Triggers**:

- New clinical guidelines published
- Major clinical trials published
- FDA safety alerts
- Journal article retraction

**Update Process**:

```markdown
[UPDATED: November 2025]

This content has been updated to reflect:

- New AHA/ACC Heart Failure Guidelines (2025)
- Results from STRONG-HF trial (NEJM, 2025)

Previous version archived and available in edit history.
```

---

## Disclaimers & Warnings

### Standard Disclaimer

**All Medical Content Includes**:

```
âš ï¸ MEDICAL DISCLAIMER

This information is for educational purposes only and does not constitute
medical advice. Always consult with a qualified healthcare provider before
making medical decisions. Individual patient circumstances vary, and treatment
should be personalized based on comprehensive clinical evaluation.
```

### Specific Content Warnings

**Off-Label Use**:

```
âš ï¸ OFF-LABEL USE

This discussion includes off-label medication uses not FDA-approved for this
indication. Discuss risks/benefits with patients. Check institutional policies.
```

**Controversial Topic**:

```
âš ï¸ CONTROVERSIAL TOPIC

This topic has conflicting evidence or expert opinions. Multiple perspectives
presented. Use clinical judgment and patient preferences when applying.
```

**Outdated Information**:

```
âš ï¸ OUTDATED INFORMATION

This content is >2 years old. Newer evidence or guidelines may be available.
Check current literature before applying clinically.
```

**Case Report**:

```
âš ï¸ CASE REPORT

Single patient case. Not generalizable. Use for educational purposes only.
Clinical decisions should be based on comprehensive evidence and guidelines.
```

---

## Quality Metrics

### Content Quality Score (0-100)

**Calculation**:

```python
def calculate_content_quality(content):
    score = 0

    # Citations (0-25 points)
    citations = count_citations(content)
    score += min(citations * 5, 25)

    # Evidence quality (0-25 points)
    evidence_level = assess_evidence_level(content)
    evidence_points = {
        '1a': 25, '1b': 20, '2a': 15, '2b': 15,
        '3': 10, '4': 5, '5': 0
    }
    score += evidence_points.get(evidence_level, 0)

    # Completeness (0-20 points)
    has_abstract = check_abstract(content)
    has_methods = check_methods(content)
    has_results = check_results(content)
    has_discussion = check_discussion(content)
    score += (has_abstract + has_methods + has_results + has_discussion) * 5

    # Clarity (0-15 points)
    readability = assess_readability(content)  # Flesch-Kincaid
    score += min(readability / 10, 15)

    # Accuracy (0-15 points)
    accuracy = verify_accuracy(content)
    score += accuracy

    return min(score, 100)
```

**Quality Badges**:

- 90-100: ğŸ† **Excellent**
- 75-89: â­ **High Quality**
- 60-74: âœ… **Good**
- 40-59: âš ï¸ **Acceptable**
- <40: âŒ **Needs Improvement**

### Platform-Wide Quality Metrics

**Target Metrics**:

- Average content quality score: >75
- % of content with peer-reviewed citations: >80%
- % of content reviewed by experts: >95% (for featured content)
- User-reported accuracy issues: <2%
- Retraction rate: <0.1%

**Monitoring Dashboard**:

```
Content Quality Metrics (Last 30 Days)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Average Quality Score:        82/100 âœ…
Content with Citations:       87%     âœ…
Expert-Reviewed Content:      94%     âš ï¸
Accuracy Flags:               1.2%    âœ…
Content Updates (outdated):   45      â„¹ï¸
Retractions:                  2       âœ…
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## Enforcement

### Violations

**Minor Violations**:

- Missing citations (warning + request to add)
- Unclear disclaimers (prompt to clarify)
- Poor formatting (editorial assistance)

**Moderate Violations**:

- Unsupported clinical claims (-10 reputation)
- Outdated information not updated (-5 reputation)
- Inadequate evidence disclosure (-5 reputation)

**Major Violations**:

- Dangerous medical advice (-50 reputation + content removal)
- Intentional misinformation (-100 reputation + suspension)
- Plagiarism (permanent ban)
- Fabricated data (permanent ban + legal action)

### Appeals

Users can appeal content removal/penalties:

1. Submit appeal with supporting evidence
2. Independent reviewer evaluates
3. Decision within 7 days
4. Reputation restored if appeal successful

---

## Conclusion

Medical Content Standards ensure Uniting Doctors maintains its reputation as a trusted, evidence-based platform for healthcare professionals. By enforcing rigorous quality standards, promoting transparency, and leveraging both AI and human expertise, we protect patient safety while fostering open medical discourse.

**Success Metrics**:

- **User Trust**: 90% of users trust content quality
- **Accuracy Rate**: 98%+ accuracy on fact-checked claims
- **Citation Rate**: 85%+ of clinical claims cited
- **Community Satisfaction**: 4.5+ stars for content quality

---

**Document Version**: 1.0
**Last Updated**: November 8, 2025
**Owner**: Clinical Standards Committee
**Related Documents**:

- [RESEARCH_INTEGRATION.md](./RESEARCH_INTEGRATION.md)
- [CONTENT_MODERATION.md](../operations/CONTENT_MODERATION.md)
- [OFF_LABEL_FRAMEWORK.md](./OFF_LABEL_FRAMEWORK.md)
